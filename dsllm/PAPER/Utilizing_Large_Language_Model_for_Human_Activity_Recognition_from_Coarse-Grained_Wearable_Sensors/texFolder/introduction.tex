\chapter{Introduction}

Human Activity Recognition (HAR) using wearable sensors has emerged as a fundamental technology for numerous applications including mobile health monitoring, sports analytics, human-computer interaction, and smart environment systems \cite{Bulling2014HARSurvey, Lara2013Mobile}. The ability to automatically identify and classify daily activities from sensor data enables continuous and unobtrusive monitoring of human behavior, providing valuable insights for healthcare, fitness tracking, and lifestyle analysis \cite{Shoaib2015Survey}.

A critical and underexplored challenge in HAR is the significant drop in recognition performance when sensor data is downsampled or collected at low temporal resolution, a scenario increasingly common in consumer-grade wearables. Reducing the sampling frequency of sensors such as accelerometers and gyroscopes can dramatically extend battery life and operational time for smart devices, making low-grain data collection highly desirable for real-world, long-term deployment. However, this comes at the cost of information loss, increased noise, and reduced discriminative power, which can severely degrade the accuracy of activity recognition models.

Traditional HAR approaches predominantly rely on motion sensors such as accelerometers, gyroscopes, and magnetometers embedded in smartphones or dedicated wearable devices \cite{Chen2021WearableHAR}. While these sensors offer the advantage of being lightweight, power-efficient, and readily available in consumer devices, they often produce coarse-grained data with limited precision compared to specialized research-grade equipment. This limitation poses significant challenges for accurate activity recognition, particularly when distinguishing between subtle variations in movement patterns or activities with similar motion characteristics.

Recent advances in deep learning have revolutionized the field of HAR, with convolutional neural networks (CNNs) and recurrent neural networks (RNNs) showing remarkable performance improvements over traditional machine learning approaches \cite{Wang2019DeepHAR, Yang2015DeepConvLSTM}. Deep learning models have demonstrated their ability to automatically extract meaningful features from raw sensor data, reducing the need for manual feature engineering \cite{Hammerla2016Deep, Ronao2016Human}. However, most existing deep learning approaches for HAR are designed for high-quality sensor data and may not perform optimally when dealing with the noisy, low-resolution signals typical of consumer-grade wearable devices \cite{Ignatov2018RealTime}.

The emergence of Large Language Models (LLMs) and transformer architectures has opened new possibilities for sequence modeling and pattern recognition across diverse domains \cite{Vaswani2017Attention}. Models such as BERT \cite{Devlin2019BERT} and GPT-3 \cite{Brown2020GPT3} have demonstrated exceptional capabilities in understanding complex sequential patterns and contextual relationships. While these models were originally designed for natural language processing tasks, their underlying transformer architecture and attention mechanisms show promise for modeling temporal sequences in other domains, including sensor data analysis.

Recent pioneering work has begun to explore the application of LLMs to sensor-based HAR. Most notably, SensorLLM \cite{li2024sensorllm} introduced a two-stage framework for aligning large language models with motion sensors for human activity recognition. Their approach involves a Sensor-Language Alignment Stage that introduces special tokens for each sensor channel and automatically generates trend-descriptive text to align sensor data with textual inputs, followed by a Task-Aware Tuning Stage for HAR classification. This work represents an important breakthrough in bridging the gap between natural language processing and sensor-based activity recognition, demonstrating that LLMs can be effectively adapted for HAR tasks through specialized training procedures.

While SensorLLM has established the foundational feasibility of LLM-based HAR, several critical challenges remain largely unaddressed, particularly for real-world deployment scenarios involving downsampled, coarse-grained wearable sensors. First, the computational requirements and memory footprint of large transformer models present significant barriers for deployment on resource-constrained wearable devices, where power efficiency and real-time processing are paramount. Second, existing approaches have primarily focused on high-quality sensor data from controlled laboratory settings, but have not adequately addressed the unique challenges posed by low-frequency, low-precision sensor signals that are characteristic of consumer-grade wearable devices. Third, the temporal resolution and sampling rates of downsampled wearable sensors may not align optimally with the sequence processing capabilities of language models, necessitating specialized data representation and tokenization strategies.

Furthermore, the application of LLMs to sensor-based HAR presents several compelling advantages that remain underexplored in the context of low-grain data. The self-attention mechanism in transformers can effectively capture long-range dependencies in temporal sensor data, potentially identifying subtle patterns that traditional approaches might miss in noisy, low-resolution signals. The pre-training paradigm used in LLMs could enable knowledge transfer from large-scale datasets to smaller, domain-specific HAR datasets, which is particularly valuable when working with limited, downsampled sensor data. Additionally, the contextual understanding capabilities of LLMs may help in disambiguating similar activities by considering broader temporal context, which is crucial when dealing with the reduced discriminative power of low-frequency sensors.

This thesis is specifically motivated by the need to enable accurate and robust HAR on downsampled (low-grain) sensor data, with the ultimate goal of enabling longer battery life and more practical, real-world deployment of smart wearable devices.

The main contributions of this work include:
\begin{enumerate}
\item A novel sensor data representation method specifically designed for downsampled, coarse-grained wearable sensor signals that transforms continuous low-frequency sensor data into discrete tokens suitable for processing by Large Language Models, with optimizations for handling noise and reduced temporal resolution.
\item An efficient LLM-based architecture that balances accuracy with computational efficiency for deployment on resource-constrained wearable devices, incorporating novel attention mechanisms and parameter reduction techniques tailored for low-grain sensor data processing.
\item Comprehensive experimental evaluation demonstrating the effectiveness of our approach on multiple public datasets under various levels of sensor downsampling and precision degradation, showing significant improvements over traditional methods and competitive performance with existing LLM-based approaches, particularly in challenging low-grain sensor data scenarios.
\item Analysis of the interpretability and attention patterns learned by the LLM-based HAR model when processing downsampled sensor data, providing insights into how the model adapts to and compensates for reduced sensor precision while maintaining activity recognition accuracy.
\end{enumerate}

The remainder of this thesis is organized as follows: Chapter 2 reviews related work in human activity recognition, deep learning approaches for sensor data analysis, and the application of transformer models to time series data, with particular emphasis on recent developments in LLM-based sensor data processing and the challenges of low-grain data. Chapter 3 presents our proposed methodology, including the downsampled sensor data tokenization approach and the efficient LLM-based HAR architecture. Chapter 4 describes the experimental setup and presents comprehensive evaluation results across multiple datasets and sensor precision levels. Chapter 5 discusses the implications of our findings, limitations of the current approach, and future research directions. Finally, Chapter 6 concludes the thesis and summarizes the key contributions.