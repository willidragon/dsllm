\chapter{Conclusion}

\hspace{2em}This thesis introduced a novel two-stage methodology that marries state-of-the-art time-series imputation with large language models for human activity recognition (HAR) from coarse-grained wearable sensors. Stage~1 employs \textbf{SAITS} to reconstruct high-resolution sensor streams from low-frequency inputs, effectively recovering fine temporal cues that would otherwise be lost in downsampling. Stage~2 fine-tunes a compact \textbf{SensorLLM} on the imputed data, coupling a Chronos encoder with a lightweight LLaMA decoder to deliver accurate, token-efficient HAR.

\hspace{2em}Comprehensive experiments on the \textit{Capture-24} benchmark demonstrate that our SAITS-enhanced pipeline not only closes but often exceeds the performance gap between low- and high-frequency sensing, outperforming strong interpolation, CNN/RNN, and transformer baselines. Ablation studies further confirm that high-quality imputation is a decisive factor in the success of LLM-based HAR under resource constraints.

\hspace{2em}By explicitly decoupling data enhancement from recognition, our approach provides a flexible blueprint for deploying sophisticated sequence models on energy-limited wearables. Future work will explore broader sensor modalities, real-time inference optimisation, and knowledge distillation to further shrink the model footprint without compromising accuracy.
