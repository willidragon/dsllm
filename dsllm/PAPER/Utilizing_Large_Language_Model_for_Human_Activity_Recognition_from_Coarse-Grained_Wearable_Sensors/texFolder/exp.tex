\chapter{Experiments}

\section{Datasets}

\subsection{Description}
\hspace{2em}We used two public datasets in our experiments. The first dataset, SleepAccel, was collected using an Apple Watch and includes motion data, heart rate, and sleep labels from PSG. Data were collected at the University of Michigan from June 2017 to March 2019, and there are 31 subjects in total. The second dataset, DREAMT, was collected using an Empatica E4 wristband. A total of 100 unique participants were recruited from the Duke University Health System (DUHS) Sleep Disorder Lab to participate in the study between May 2022 and September 2022. The total counts and distribution of the data are shown in the table below.

\begin{table}[h]
\centering
\caption{Label Counts and Distribution for SleepAccel and DREAMT Datasets}
\begin{tabular}{|c|c|c|c|c|c|}
\hline
\textbf{Dataset} & \textbf{WAKE} & \textbf{N1} & \textbf{N2} & \textbf{N3} & \textbf{REM} \\ \hline
\multicolumn{6}{|c|}{\textbf{Counts}} \\ \hline
SleepAccel       & 2,133         & 1,624       & 12,184       & 3,189       & 5,427           \\ \hline
DREAMT           & 19,971        & 8,819       & 39,687      & 2,661       & 8,331           \\ \hline
\multicolumn{6}{|c|}{\textbf{Percentage (\%)}} \\ \hline
SleepAccel       & 8.7\%       & 6.6\%     & 49.6\%     & 13\%     & 22.1\%          \\ \hline
DREAMT           & 25.1\%       & 11.1\%     & 49.9\%     & 3.3\%     & 10.5\%          \\ \hline
\end{tabular}
\end{table}

\subsection{Preprocessing}

\hspace{2em}Due to the different sampling frequencies of sensors in the datasets, such as the heart rate at 64 Hz and motion at 32 Hz in the DREAMT dataset, and heart rate at 0.2 Hz and motion at 50 Hz in the SleepAccel dataset, it was necessary to align these data for analysis. To synchronize the data and preserve more temporal information, interpolation was used to upsample all data to 64 Hz. However, this process can introduce some artifacts, so future work may consider a compromise approach, such as upsampling some data while downsampling others.

Additionally, because the data includes preparation and measurement start stages, it is possible to accurately determine the start time of measurement for users. Therefore, in addition to three-axis accelerometer data and heart rate data, a relative time difference to the start of measurement (or lights-off) was added as a feature.

To further preprocess the data, Interquartile Range (IQR) normalization was applied to the 3-axis acceleration data and heart rate data. IQR normalization helps to reduce the impact of outliers by scaling the data based on the interquartile range, thus ensuring a more robust and stable input for the model.

\section{Baselines}

\hspace{2em}We compare our proposed model with one baseline method that aim to reduce computational costs, more baselines would be further implemented:

\begin{itemize}
    \item \textbf{CNN-Transformer}: This model uses four convolutional layers followed by the encoder component of a transformer. It is designed to leverage both convolutional and transformer architectures to achieve efficient feature extraction and sequence modeling.
\end{itemize}


\section{Experiment Setting}

\hspace{2em}We set the hyperparameter \(\beta\) in the Class-Balanced Softmax Cross Entropy to 0.99 and the confidence threshold \(\theta\) to 0.7. The Adam optimizer is used with a learning rate of 0.01, and the batch size is set to 512.

To ensure robust model validation and to prevent overfitting, we employ stratified 5-fold cross-validation. This technique involves splitting the training data into five equal parts, or folds, while maintaining the class distribution within each fold. The model is trained on four folds and validated on the remaining fold. This process is repeated five times, with each fold used exactly once for validation. The cross-validation process helps in assessing the model’s performance more reliably, as it ensures that each data point has been used for both training and validation, thereby providing a comprehensive evaluation of the model’s ability to generalize to unseen data.

\begin{table}[h]
\centering
\caption{Experiment Settings}
\begin{tabular}{|l|c|}
\hline
\textbf{Setting} & \textbf{Value} \\ \hline
\(\beta\) in Class-Balanced Softmax & 0.99 \\ \hline
Cross-Validation & Stratified 5-Fold \\ \hline
Learning Rate & 0.01 \\ \hline
Batch Size & 512 \\ \hline
Confidence Threshold \(\theta\) & 0.8 \\ \hline
\end{tabular}
\end{table}

\section{Evaluation Metrics}

\hspace{2em}To comprehensively evaluate the performance of the proposed model, we employ several evaluation metrics that capture different aspects of model effectiveness and efficiency. These metrics include accuracy, macro F1-score, Cohen's kappa, FLOPs (Floating Point Operations), and the number of model parameters.

\subsection{Accuracy}
Accuracy measures the proportion of correctly classified instances among the total instances. It is a straightforward metric but can be misleading in the case of imbalanced datasets. Accuracy is defined as:

\[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\]

where \(TP\) stands for True Positives, \(TN\) for True Negatives, \(FP\) for False Positives, and \(FN\) for False Negatives.

\subsection{Macro F1-Score}
\hspace{2em}The macro F1-score is the harmonic mean of precision and recall, calculated for each class independently and then averaged. This metric gives equal weight to each class, making it particularly useful for evaluating performance on imbalanced datasets. The macro F1-score is defined as:

\[
\text{F1-score} = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\]

\[
\text{Macro F1-score} = \frac{1}{C} \sum_{i=1}^{C} \text{F1-score}_i
\]

where \(C\) is the number of classes.

\subsection{Cohen's Kappa}
\hspace{2em}Cohen's kappa measures the agreement between predicted and true labels, taking into account the possibility of agreement occurring by chance. It is particularly useful for imbalanced datasets. Cohen's kappa is defined as:

\[
\kappa = \frac{p_o - p_e}{1 - p_e}
\]

where \(p_o\) is the observed agreement, and \(p_e\) is the expected agreement by chance.

\subsection{FLOPs (Floating Point Operations)}

\hspace{2em}FLOPs measure the computational complexity of the model by counting the number of floating-point operations required to make a prediction. This metric is crucial for evaluating the computational efficiency and feasibility of deploying the model on resource-constrained devices.

\subsection{Model Parameters}
\hspace{2em}The number of model parameters is an important metric for understanding the model's complexity and potential overfitting. A model with fewer parameters is generally more efficient and suitable for deployment on devices with limited computational resources.

By using these evaluation metrics, we aim to provide a comprehensive assessment of the model's performance, balancing accuracy, robustness, and computational efficiency to ensure its practical applicability for sleep stage classification on consumer wearable devices.

\section{Performance Comparison}

\subsection{Performance Result}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CNNTransformer & \textbf{0.787} & \textbf{0.7133} & \textbf{0.6932} & 9.8566 & 384.837  \\
        Proposed Method (0.8) & 0.7267 & 0.6476 & 0.6073 & \textbf{2.0104} & \textbf{32.01} \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics between baseline and proposed methods on the SleepAccel dataset.}
    \label{tab:performance_comparison_sleepaccel}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CNNTransformer & \textbf{0.697} & \textbf{0.6178} & \textbf{0.54} & 9.8566 & 384.837  \\
        Proposed Method (0.8) & 0.6308 & 0.5377 & 0.4479 & \textbf{2.0104} & \textbf{32.01} \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics between baseline and proposed methods on the DREAMT dataset.}
    \label{tab:performance_comparison_dreamt}
\end{table}

% Tables \ref{tab:performance_comparison_sleepaccel} and \ref{tab:performance_comparison_dreamt} compare the performance of the CNNTransformer baseline model with the proposed method on two different datasets: SleepAccel and DREAMT. The results indicate that the proposed method successfully reduces the computational cost by approximately 80\% and the number of parameters by nearly 90\%. Despite this significant reduction in computational complexity, there is a notable trade-off in performance metrics such as accuracy, F1 score, and Cohen's kappa.

% Figure \ref{fig:performance-combine-simple-deep} illustrates the confusion matrices of the proposed method on the SleepAccel dataset. The confusion matrices are presented for the combined output, the simple classifier, and the deep classifier. The simple classifier demonstrates high accuracy, showing its effectiveness in reducing computational costs while maintaining reasonable performance. However, the performance for the N1 sleep stage is particularly poor due to the limited number of samples available for this stage, which affects the model's ability to generalize effectively. The deep classifier is employed to capture more intricate features, improving overall performance in more complex cases.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{figs/performance-combine-simple-deep.png}
    \caption{Confusion matrix of the proposed method on the SleepAccel dataset: (a) Combined output (b) Simple Classifier output (c) Deep Classifier output}
    \label{fig:performance-combine-simple-deep}
\end{figure}

\subsection{Performance on Different Confidence Thresholds}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        COPS-CD-1 & \textbf{0.7423} & \textbf{0.6643} & \textbf{0.6278} & 2.0330 & \textbf{31.685}\\
        COPS-CD-0.9 & 0.7354 & 0.6557 & 0.6173 & 2.0256 & 32.01 \\
        COPS-CD-0.8 & 0.7391 & 0.6576 & 0.6227 & 2.0098 & 32.01 \\
        COPS-CD-0.7 & 0.7276 & 0.6496 & 0.6094 & 1.9705 & 32.01 \\
        COPS-CD-0.6 & 0.7130 & 0.6319 & 0.5890 & \textbf{1.8962} & 32.01 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds on the SleepAccel dataset.}
    \label{tab:performance_of_different_confidence}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        COPS-CD-1 & \textbf{0.6273} & \textbf{0.5275} & \textbf{0.4353} & 2.0330 & \textbf{31.685}\\
        COPS-CD-0.9 & 0.6227 & 0.5187 & 0.4325 & 2.0263 & 32.01 \\
        COPS-CD-0.8 & 0.6197 & 0.5166 & 0.4302 & 2.0157 & 32.01 \\
        COPS-CD-0.7 & 0.6223 & 0.5246 & \textbf{0.4353} & 2.0034 & 32.01 \\
        COPS-CD-0.6 & 0.6201 & 0.5189 & 0.4326 & \textbf{1.9812} & 32.01 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds on the DREAMT dataset.}
    \label{tab:performance_of_different_confidence}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CDL-CD-1 & 0.7884 & \textbf{0.7138} & 0.6948 & 9.8566 & \textbf{384.837}\\
        CDL-CD-0.9 & \textbf{0.7907} & 0.7123 & \textbf{0.7019} & 9.1792 & 386.452 \\
        CDL-CD-0.8 & 0.7687 & 0.6925 & 0.6727 & 8.8275 & 386.452 \\
        CDL-CD-0.7 & 0.7562 & 0.6734 & 0.6538 & 8.3180 & 386.452 \\
        CDL-CD-0.6 & 0.7077 & 0.6167 & 0.5866 & \textbf{7.6957} & 386.452 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds for the CNNTransroemer on the SleepAccel dataset.}
    \label{tab:performance_of_different_confidence}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CDL-CD-1 & 0.6943 & 0.6202 & 0.5429 & 9.8566 & 384.837\\
        CDL-CD-0.9 & 0.6812 & 0.6006 & 0.5370 & 9.4794 & 386.452 \\
        CDL-CD-0.8 & 0.6728 & 0.5801 & 0.5246 & 9.2373 & 386.452 \\
        CDL-CD-0.7 & 0.6337 & 0.5443 & 0.4789 & 8.9522 & 386.452 \\
        CDL-CD-0.6 & 0.6248 & 0.5370 & 0.4652 & 8.5095 & 386.452 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds for the CNNTransroemer on the DREAMT dataset.}
    \label{tab:performance_of_different_confidence}
\end{table}


% Tables \ref{tab:performance_of_different_confidence} 


\subsection{Implementation of Confidence Threshold on Baseline}

% \hspace{2em} Table \ref{tab:performance_of_baseline_with_confidence} 

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CNNTransformer & 0.7870 & 0.7133 & 0.6932 & 9.8566 & \textbf{384.837}\\
        CNNTransformer (0.8) & \textbf{0.7978} & \textbf{0.7235} & \textbf{0.7071} & \textbf{8.9325} & 386.452 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds for the CNNTransformer baseline.}
    \label{tab:performance_of_baseline_with_confidence}
\end{table}



\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CDL-Deeponly & 0.7944 & 0.7220 & 0.7030 & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-2 & 0.7963 & 0.7264 & 0.7072 & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-1 & \textbf{0.7974} & \textbf{0.7282} & \textbf{0.7084} & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-0.9 & 0.7919 & 0.7211 & 0.7011 & 9.8570 & 385.162 \\
        CDL-CD-0.8 & 0.7849 & 0.7126 & 0.6925 & 9.8570 & 385.162 \\
        CDL-CD-0.7 & 0.7801 & 0.7072 & 0.6853 & 9.8570 & 385.162 \\
        CDL-CD-0.6 & 0.7671 & 0.6921 & 0.6649 & 9.8570 & 385.162 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds for the CNNTransroemer-CD-one on the SleepAccel dataset.}
    \label{tab:performance_of_different_confidence}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CDL-Deeponly & 0.7944 & 0.7220 & 0.7030 & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-2 & \textbf{0.8017} & 0.7312 & \textbf{0.7137} & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-1 & 0.7951 & \textbf{0.7263} & 0.7049 & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-0.9 & 0.7893 & 0.7151 & 0.6991 & 9.8573 & 385.482 \\
        CDL-CD-0.8 & 0.7868 & 0.7105 & 0.6949 & 9.8573 & 385.482 \\
        CDL-CD-0.7 & 0.7799 & 0.7033 & 0.6853 & 9.8573 & 385.482 \\
        CDL-CD-0.6 & 0.7657 & 0.6861 & 0.6638 & 9.8573 & 385.482 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds for the CNNTransroemer-CD-two on the SleepAccel dataset.}
    \label{tab:performance_of_different_confidence}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CDL-Deeponly & 0.7944 & 0.7220 & 0.7030 & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-2 & 0.7944 & 0.7265 & 0.7086 & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-1 & \textbf{0.7980} & \textbf{0.7271} & \textbf{0.7091} & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-0.9 & 0.7978 & 0.7166 & 0.6984 & 9.8573 & 385.482 \\
        CDL-CD-0.8 & 0.7889 & 0.7097 & 0.6955 & 9.8573 & 385.482 \\
        CDL-CD-0.7 & 0.7821 & 0.7083 & 0.6876 & 9.8573 & 385.482 \\
        CDL-CD-0.6 & 0.7589 & 0.6808 & 0.6547 & 9.8573 & 385.482 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds for the CNNTransroemer-CD-three on the SleepAccel dataset.}
    \label{tab:performance_of_different_confidence}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CDL-Deeponly & 0.6965 & 0.6207 & 0.5450 & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-2 & 0.7003 & 0.6307 & 0.5555 & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-1 & 0.7037 & 0.6343 & 0.5594 & \textbf{9.8566} & \textbf{384.837}\\
        CDL-CD-0.9 & 0.6914 & 0.6125 & 0.5428 & 9.8570 & 385.162 \\
        CDL-CD-0.8 & 0.6952 & 0.6143 & 0.5474 & 9.8570 & 385.162 \\
        CDL-CD-0.7 & 0.6825 & 0.5971 & 0.5316 & 9.8570 & 385.162 \\
        CDL-CD-0.6 & 0.6759 & 0.5872 & 0.5223 & 9.8570 & 385.162 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds for the CNNTransroemer-CD-one on the DREAMT dataset.}
    \label{tab:performance_of_different_confidence}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CDL-Deeponly & 0.6965 & 0.6207 & 0.5450 & 9.8566 & 384.837\\
        CDL-CD-2 & 0.7029 & 0.6309 & 0.5587 & 9.8566 & 384.837\\
        CDL-CD-1 & 0.6944 & 0.6276 & 0.5504 & 9.8566 & 384.837\\
        CDL-CD-0.9 & 0.6901 & 0.6034 & 0.5416 & 9.8573 & 385.482 \\
        CDL-CD-0.8 & 0.6721 & 0.5828 & 0.5191 & 9.8573 & 385.482 \\
        CDL-CD-0.7 & 0.6557 & 0.5671 & 0.5009 & 9.8573 & 385.482 \\
        CDL-CD-0.6 & 0.6473 & 0.5538 & 0.4859 & 9.8573 & 385.482 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds for the CNNTransroemer-CD-two on the DREAMT dataset.}
    \label{tab:performance_of_different_confidence}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CDL-Deeponly & 0.6965 & 0.6207 & 0.5450 & 9.8566 & 384.837\\
        CDL-CD-2 & 0.7042 & 0.6329 & 0.5605 & 9.8566 & 384.837\\
        CDL-CD-1 & 0.6952 & 0.6261 & 0.5519 & 9.8566 & 384.837\\
        CDL-CD-0.9 & 0.6850 & 0.6080 & 0.5376 & 9.8573 & 385.482 \\
        CDL-CD-0.8 & 0.6617 & 0.5822 & 0.5118 & 9.8573 & 385.482 \\
        CDL-CD-0.7 & 0.6535 & 0.5626 & 0.4975 & 9.8573 & 385.482 \\
        CDL-CD-0.6 & 0.6468 & 0.5517 & 0.4854 & 9.8573 & 385.482 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds for the CNNTransroemer-CD-three on the DREAMT dataset.}
    \label{tab:performance_of_different_confidence}
\end{table}

\begin{table}[ht]
    \centering
    \begin{tabular}{lcccccc}
        \toprule
        Method (\(\theta\)) & Accuracy & F1 Score & Cohen's Kappa & FLOPs (M) & Parameters (K) \\
        \midrule
        CDL-Deeponly & 0.7944 & 0.7220 & 0.7030 & 9.8566 & 384.837\\
        CDL-CD-2 & 0.7944 & 0.7265 & 0.7086 & 9.8566 & 384.837\\
        CDL-CD-1 & 0.7980 & 0.7271 & 0.7091 & 9.8566 & 384.837\\
        CDL-CD-0.9 & 0.7978 & 0.7166 & 0.6984 & 9.8573 & 385.482 \\
        CDL-CD-0.8 & 0.7889 & 0.7097 & 0.6955 & 9.8573 & 385.482 \\
        CDL-CD-0.7 & 0.7821 & 0.7083 & 0.6876 & 9.8573 & 385.482 \\
        CDL-CD-0.6 & 0.7589 & 0.6808 & 0.6547 & 9.8573 & 385.482 \\
        \bottomrule
    \end{tabular}
    \caption{Comparison of performance metrics at different confidence thresholds for the CNNTransroemer-CD-three on the DREAMT dataset.}
    \label{tab:performance_of_different_confidence}
\end{table}